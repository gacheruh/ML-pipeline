{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37a1520",
   "metadata": {},
   "source": [
    "# Pipeline in Machine Learning using Random Forest Regressor\n",
    "\n",
    "In Machine Learning, data preprocessing is an important step before fitting a model. It includes various operations such as handling missing values, scaling the features, and encoding the categorical variables. Pipeline is a useful tool in Machine Learning that helps us to chain multiple operations together in a specific sequence.\n",
    "\n",
    "Pipeline can be used to automate the workflow of a machine learning model. It allows us to combine the data preprocessing steps and model building steps into a single object. Pipeline is also helpful in avoiding data leakage, where information from the test data is accidentally used to train the model.\n",
    "\n",
    "In this example, we will use Pipeline to create a workflow for a Random Forest Regressor. The Random Forest Regressor is a popular ensemble learning algorithm that can be used for regression problems. It combines multiple decision trees to reduce overfitting and improve the accuracy of the model.\n",
    "\n",
    "To create a Pipeline for a Random Forest Regressor, we first need to define the data preprocessing steps that will be included in the Pipeline. These steps can be defined using the transformers available in scikit-learn. For example, we can use the **SimpleImputer** transformer to fill the missing values and **StandardScaler** to scale the data. We can also use the **ColumnTransformer** to apply different transformers to different columns in the dataset.\n",
    "\n",
    "Once we have defined the transformers, we can create a Pipeline object that includes these transformers and the Random Forest Regressor. The Pipeline object can be trained and tested like any other machine learning model.\n",
    "\n",
    "Finally, we can use cross-validation to evaluate the performance of the Pipeline. Cross-validation is a technique that allows us to estimate the generalization error of the model. It involves splitting the dataset into multiple folds, training the model on some folds, and testing it on the remaining folds. We can use the **cross_val_score** function from scikit-learn to perform cross-validation.\n",
    "\n",
    "Overall, Pipeline is a powerful tool in Machine Learning that can help us to streamline our workflow and improve the accuracy of our models. It allows us to automate the data preprocessing steps and build more complex models that can handle diverse datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8922b30",
   "metadata": {},
   "source": [
    "## Predicting House Prices in Melbourne, Australia using Random Forest Regressor\n",
    "\n",
    "In this project, we will use a Random Forest Regressor (RFR) to predict house prices in Melbourne, Australia. The dataset contains various features of the houses such as the number of rooms, land size, location, and distance to the city center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b93ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.read_csv('../melb_data.csv')\n",
    "\n",
    "#dropping missing values in the Price column\n",
    "X.dropna(axis = 0, subset = ['Price'],  inplace = True)\n",
    "y = X.Price\n",
    "X.drop('Price', axis = 1, inplace = True)\n",
    "\n",
    "#Splitting the data into training and validation data sets\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size = 0.8, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba423b3d",
   "metadata": {},
   "source": [
    "### Preprocessing the data\n",
    "\n",
    "Before we can train our model, we need to preprocess our data. This includes filling in missing values and one-hot encoding categorical features. We will use a pipeline to automate this process.\n",
    "\n",
    "#### 1. Defining numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a02938a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the columns into numerical and categorical columns\n",
    "numerical_cols = [col for col in X_train_full.columns if X_train_full[col].dtype in ['int64', 'float64']]\n",
    "categorical_cols = [col for col in X_train_full.columns if X_train_full[col].nunique() < 10 and X_train_full[col].dtype == 'object']\n",
    "\n",
    "#To keep only the selected columns only\n",
    "new_cols = numerical_cols + categorical_cols\n",
    "X_train = X_train_full[new_cols].copy()\n",
    "X_valid = X_valid_full[new_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c58cf",
   "metadata": {},
   "source": [
    "#### 2, Defining transformers and creating a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbbe3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "numerical_transformer = SimpleImputer(strategy = 'median')\n",
    "categorical_transformer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1350c50",
   "metadata": {},
   "source": [
    "We will then use ColumnTransformer to combine the transformers into a preprocessor object, which will apply the appropriate transformations to the numerical and categorical data. We will then combine the preprocessor with the RFR into a single pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cec6ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the preprocessor to transform the columns\n",
    "preprocessor = ColumnTransformer(transformers = [\n",
    "    ('num', numerical_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "#Creating the pipeline\n",
    "pipeline = Pipeline(steps = [\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators = 100, random_state = 1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c783a890",
   "metadata": {},
   "source": [
    "We can now fit the pipeline on the training data and evaluate it on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d0420e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 156193.93891384391\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model to the training sets\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "#prediction using the pipeline\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "\n",
    "#Calculating the mean absolute error of the model\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_pred, y_valid)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01954082",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Finally, we can use cross-validation to get a better estimate of the model's performance. We will use the cross_val_score function from Scikit-learn's model_selection module to perform a 5-fold cross-validation on the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfc16b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208568.39890508 192120.81007504 187337.02170822 153314.20272047\n",
      " 156316.23232678]\n",
      "MEAN: 179531.3331471176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "scores = -1 * cross_val_score(pipeline, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Print the average score across\n",
    "print(scores)\n",
    "print((f'MEAN: {scores.mean()}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0d5dfe",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we have used a Random Forest Regressor to predict house prices in Melbourne, Australia. We have preprocessed our data using a pipeline and evaluated the performance of our model using cross-validation and a held-out test set. The model achieved a mean absolute error of 156193.93891384391, indicating that it can accurately predict house prices.\n",
    "\n",
    "In conclusion, pipelines in machine learning provide a powerful tool for automating the preprocessing and modeling stages of a machine learning workflow. It allows for easy and efficient preprocessing of both numerical and categorical data, reducing the amount of code needed to transform and scale the data. Additionally, it streamlines the modeling process, allowing for the quick and easy testing of various models and hyperparameters.\n",
    "\n",
    "Pipelines also help in reducing the risk of data leakage, ensuring that the preprocessing steps are performed only on the training set and not the entire dataset. This reduces the risk of overfitting and ensures that the model is not biased towards the training data.\n",
    "\n",
    "Overall, pipelines provide a simplified approach to machine learning, reducing the amount of code required and automating the process. It helps in building robust, scalable and efficient models, and is highly recommended for use in machine learning workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
